{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anderson-ferreira-83/Data_Science_Repo_anderson83/blob/main/1_Alura_Voz/Week_1_data_cleaning/p1_Cleaning_for_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXbN4yRzMb_w"
      },
      "source": [
        "## Part 1 - Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os # imports the os module for operating system related functionalities\n",
        "import sys # imports the sys module for system-specific parameters and functions"
      ],
      "metadata": {
        "id": "3KV9dy-3umB1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gdown\n"
      ],
      "metadata": {
        "id": "yjp2ohLY6Zm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_data_telco_cust_churn_file='1DPIC3QOFiKuYpBnnjOfUcLCfmoqOBRIZ'\n",
        "!gdown --id $str_data_telco_cust_churn_file\n"
      ],
      "metadata": {
        "id": "slgW4IWZSt3h",
        "outputId": "521cd09f-2fbd-49b1-aa9b-bcf05d16021a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DPIC3QOFiKuYpBnnjOfUcLCfmoqOBRIZ\n",
            "To: /content/Telco-Customer-Churn.json\n",
            "100% 3.81M/3.81M [00:00<00:00, 136MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYr439iVMb_x"
      },
      "source": [
        "Welcome to the Data Science Challenge Notebook - Week 1!\n",
        "\n",
        "In this notebook, we will be cleaning and processing the data obtained from the Alura Voz API, a telecommunications company.\n",
        "\n",
        "<p align = 'center'>\n",
        "<img src = 'https://i.imgur.com/8LTNXxF.jpg'>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGtMBRikMb_y"
      },
      "source": [
        "### Importing the Data from the API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-kNKWlAMb_y"
      },
      "source": [
        "The first step to start the data processing is to install and import the necessary libraries. We will use the `pandas` library and the `numpy` library. The documentation for both libraries can be accessed below:\n",
        "\n",
        " - [Pandas documentation](https://pandas.pydata.org/docs/)\n",
        " - [Numpy documentation](https://numpy.org/doc/stable/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rM98sGQyMb_y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # imports the pandas library for data manipulation and analysis\n",
        "import numpy as np # imports the numpy library for numerical computing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68eOdD5RMb_z"
      },
      "source": [
        "To read a JSON file, you can use the `pd.read_json()` method, passing the file path as a parameter to the method\n",
        "\n",
        "*This procedure is demonstrated in the lesson [Loading data](https://cursos.alura.com.br/course/python-pandas-tecnicas-avancadas/task/91739) from the course [Python Pandas: técnicas avançadas](https://cursos.alura.com.br/course/python-pandas-tecnicas-avancadas)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjV4lL5MMb_z"
      },
      "outputs": [],
      "source": [
        "data = pd.read_json(\"Telco-Customer-Churn.json\") # reads data from a JSON file into a pandas DataFrame\n",
        "data.head() # displays the first few rows of the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbuuvJKZMb_0"
      },
      "source": [
        "### Exploring the content of each column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISmCtsKLMb_0"
      },
      "source": [
        "Since the columns **customer, phone, internet,** and **account** contain multiple values within keys, making it difficult to analyze just by looking at the table, let's unpack the first element of each of these columns to understand them better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHFhmhp7Mb_0"
      },
      "outputs": [],
      "source": [
        "data.customer[0] # accesses and displays the first element of the 'customer' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1S1UNZWMb_0"
      },
      "outputs": [],
      "source": [
        "data.phone[0] # accesses and displays the first element of the 'phone' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaOnDgD-Mb_0"
      },
      "outputs": [],
      "source": [
        "data.internet[0] # accesses and displays the first element of the 'internet' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyhxaI3EMb_1"
      },
      "outputs": [],
      "source": [
        "data.account[0] # accesses and displays the first element of the 'account' column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzuFPgI8Mb_1"
      },
      "source": [
        "We noticed that the elements in the columns **customer, phone, internet,** and **account** are dictionaries and contain a lot of condensed information. As they are currently organized, it is very difficult to perform any analysis, so it will be necessary to transform each piece of information into a new column in the DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-9y6s75Mb_1"
      },
      "source": [
        "### Normalizing the data in each column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wClhbImDMb_1"
      },
      "source": [
        "To transform the data into new columns, we will use the `pd.json_normalize()` method. This method maps each key of the dictionary to a new column, and the contained values become the rows.\n",
        "\n",
        "We need to perform this procedure for each of the columns **customer, phone, internet,** and **account,** storing the result in variables to be merged later.\n",
        "\n",
        "*This procedure is demonstrated in the lesson[Transforming JSON Data to a Table](https://cursos.alura.com.br/course/python-pandas-tecnicas-avancadas/task/91745) from the course [Python Pandas: Advanced Techniques.](https://cursos.alura.com.br/course/python-pandas-tecnicas-avancadas)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFLGSNr1Mb_1"
      },
      "outputs": [],
      "source": [
        "customer_data = pd.json_normalize(data.customer) # normalizes the 'customer' column and stores it in a new DataFrame\n",
        "customer_data # displays the new DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22dARXOgMb_1"
      },
      "outputs": [],
      "source": [
        "phone_data = pd.json_normalize(data.phone) # normalizes the 'phone' column and stores it in a new DataFrame\n",
        "phone_data # displays the new DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37aViCjQMb_1"
      },
      "outputs": [],
      "source": [
        "internet_data = pd.json_normalize(data.internet) # normalizes the 'internet' column and stores it in a new DataFrame\n",
        "internet_data # displays the new DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Waqb9nAjMb_2"
      },
      "outputs": [],
      "source": [
        "account_data = pd.json_normalize(data.account, sep='') # normalizes the 'account' column and stores it in a new DataFrame\n",
        "account_data # displays the new DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN48g_vAMb_2"
      },
      "source": [
        "### Combining all normalizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f74yVgKWMb_2"
      },
      "source": [
        "To combine the information, you need to use the `pd.concat()` method.\n",
        "\n",
        "We have built a function to normalize the JSON objects and combine the information into a DataFrame.\n",
        "\n",
        "*This procedure is demonstrated in the lesson [Stacking DataFrames](https://cursos.alura.com.br/course/python-pandas-tecnicas-avancadas/task/91755) from the course [Python Pandas: técnicas avançadas](https://cursos.alura.com.br/course/python-pandas-tecnicas-avancadas)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbRbsiDPMb_2"
      },
      "outputs": [],
      "source": [
        "# Function to normalize JSON objects and combine information into a DataFrame\n",
        "def normalize_json(dataframe):\n",
        "    return_dataframe = pd.DataFrame()\n",
        "    for column in list(data.columns[2:]):\n",
        "        dataframe_column = pd.json_normalize(dataframe[column])\n",
        "        return_dataframe = pd.concat([return_dataframe, dataframe_column], axis=1)\n",
        "\n",
        "    return pd.concat([dataframe[list(data.columns[:2])], return_dataframe], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dveBj4zaMb_2"
      },
      "outputs": [],
      "source": [
        "# Applying the normalize_json function to the data\n",
        "data = normalize_json(data)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1WW-zOXMb_2"
      },
      "source": [
        "Using the `info()` method, we can view all the columns that were generated from the concatenation of the DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhczz_K5Mb_2"
      },
      "outputs": [],
      "source": [
        "# Displaying information about the DataFrame\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3sOZNeGMb_3"
      },
      "source": [
        "Let's use the `value_counts()` method on each of the columns to identify possible categories with incorrect or inconsistent names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOYmMioBMb_3"
      },
      "outputs": [],
      "source": [
        "# Looping through each column and printing the value counts\n",
        "for col in data.columns:\n",
        "    print('---')\n",
        "    print(data[col].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGkSaEdBMb_3"
      },
      "source": [
        "It is noticeable in the Churn variable that there is an unnamed category, representing missing data. Missing data does not provide useful information for analysis, so we should remove it from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM8o3y7NMb_3"
      },
      "outputs": [],
      "source": [
        "# Printing the value counts for the 'Churn' column\n",
        "data['Churn'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDAY7av7Mb_3"
      },
      "source": [
        "To remove the data with empty names, we select the rows in the Churn column where the name is not empty (''). We store the result in the variable `dados`.\n",
        "\n",
        "*This procedure is demonstrated in the lesson[Selection frequencies](https://cursos.alura.com.br/course/introducao-python-pandas/task/40991) do curso [Python Pandas: Handling and Analyzing Data](https://cursos.alura.com.br/course/introducao-python-pandas)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAmDZkJOMb_3"
      },
      "outputs": [],
      "source": [
        "# Printing the value counts for the 'Churn' column\n",
        "data = data[data['Churn']!= '']\n",
        "data.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mVLV4ZvMb_3"
      },
      "source": [
        "At the end of the code execution, we can identify that the Churn variable no longer has an empty name class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2nNv3xWMb_3"
      },
      "outputs": [],
      "source": [
        "# Printing the value counts for the 'Churn' column\n",
        "data['Churn'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fWzs6d2Mb_3"
      },
      "source": [
        "Another column that has empty data (' ') is **Charges.Total**. This column is related to **Charges.Monthly** and tenure.\n",
        "\n",
        "The tenure column represents the number of months the customer has subscribed to the service. The **Charges.Monthly** column represents the customer's monthly expenses, and **Charges.Total** is the total amount of expenses, which would be a multiplication of **Charges.Monthly** by tenure.\n",
        "\n",
        "Let's select all rows where tenure = 0, that is, customers who subscribed to the service for 0 months, and show the results for the columns **Charges.Total** and **Charges.Monthly**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0gBLKynMb_3"
      },
      "outputs": [],
      "source": [
        "data.query('tenure == 0')[['Charges.Total', 'Charges.Monthly', 'tenure']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJJVtZ7JMb_4"
      },
      "source": [
        "We observed that when tenure = 0, the data in **Charges.Total** is empty (' ').\n",
        "\n",
        "Now let's select the data where **Charges.Total** = ' ', showing the results for **Charges.Monthly** and tenure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl7Jm-GZMb_4"
      },
      "outputs": [],
      "source": [
        "# Pegando todas as linhas onde a coluna \"Charges.Total\" é vazia.\n",
        "data[data['Charges.Total'] == ' '][['Charges.Total', 'Charges.Monthly', 'tenure']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFerPzOgMb_4"
      },
      "source": [
        "It is noticeable that all rows in **Charges.Total** that are empty are because the customer did not subscribe for even one month. We need to fill this value with the same value that is present in **Charges.Monthly** since this represents the total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjeMZkHsMb_8"
      },
      "outputs": [],
      "source": [
        "idx = data[data['Charges.Total'] == ' '].index\n",
        "data.loc[idx, \"Charges.Total\"] = data.loc[idx, \"Charges.Monthly\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu4fwzuQMb_8"
      },
      "outputs": [],
      "source": [
        "data.query('tenure == 0')[['Charges.Total', 'Charges.Monthly', 'tenure']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXs6Yk8qMb_8"
      },
      "source": [
        "Finally, let's change the variable type to float, since it was previously set as an object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psj4EkQHMb_8"
      },
      "outputs": [],
      "source": [
        "data['Charges.Total'] = data['Charges.Total'].astype('float64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRKGRhm4Mb_8"
      },
      "source": [
        "Finally, let's store the processed data in a file Telco-Customer-Churn-limpeza.json in the Dados folder using the `to_json()` method.\n",
        "\n",
        "The data can be stored in any file format, for example, CSV using the `to_csv()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAi40RfyMb_8"
      },
      "outputs": [],
      "source": [
        "data.to_json('Telco-Customer-Churn-clean.json')"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "ac38afbc233053bffaa5b2c1a9947d7ab4ab0c21d904164870f54ce052051626"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('notebook')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}