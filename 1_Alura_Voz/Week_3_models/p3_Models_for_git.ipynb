{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anderson-ferreira-83/Data_Science_Repo_anderson83/blob/main/1_Alura_Voz/Week_3_models/p3_Models_for_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 - Model Analysis"
      ],
      "metadata": {
        "id": "Jl3CXSD0jXwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "C-TDGXgg0ImO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "RygyMsdH0YXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTe1NvF2fMlI"
      },
      "source": [
        "Having processed and analyzed the data, we can now build classification models that will be useful for Alura Voz. Among the models we can create are SVC, Decision Tree and Random Forest.\n",
        "\n",
        "### Importing libraries\n",
        "\n",
        "For the application we will use `pandas`, `seaborn`, `sklearn`, `imblearn` and `sys`. To learn more about the sklearn and imblearn libraries, access the documentation:\n",
        "- [Scikit Learn](https://scikit-learn.org/stable/); and\n",
        "- [Imbalanced Learn](https://imbalanced-learn.org/stable/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "str_utils = '1DJEF0jli6eQixbcz-ARBX7X5d9ojoP4J'"
      ],
      "metadata": {
        "id": "0QsjMLkp1XhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "!gdown --id $str_utils"
      ],
      "metadata": {
        "id": "O0eXnPr6ioXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from utils import plot_countplot,plot_matrix_confusion, compare_models_metrics"
      ],
      "metadata": {
        "id": "fZYzkkrF1QE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4bKQQr8fMlM"
      },
      "outputs": [],
      "source": [
        "#\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "#\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJM8skxefMlN"
      },
      "source": [
        "### Applying encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC32YFw7fMlN"
      },
      "source": [
        "The database is read using the pandas `read_json` method."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "str_data_telco_cust_chrun_clean_file = '1--WyhFs-oY4xjPXyHd5Qatpio-2Z4zFa'"
      ],
      "metadata": {
        "id": "duz0Iq-O2WHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "!gdown --id $str_data_telco_cust_chrun_clean_file"
      ],
      "metadata": {
        "id": "OX4JkRpVit7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF7NoynyfMlN"
      },
      "outputs": [],
      "source": [
        "#\n",
        "data = pd.read_json(\"Telco-Customer-Churn-clean.json\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95Lt7r9pfMlO"
      },
      "source": [
        "Now, we need to remove some columns that are not so important for the analysis we want to perform. The method that allows us to remove columns is `drop()` from the pandas library.\n",
        "\n",
        "There are two columns that are not interesting for the analysis and that will be removed:\n",
        "\n",
        "* `customerID` column: Its value is unique for each row and does not provide us with relevant information for an analysis, so we can remove it; and\n",
        "* `Charges.Total` column: this column contains information about the months of `Charges.Monthly` multiplied by `tenure`, so it is \"duplicate\" information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF1GUyJpfMlO"
      },
      "outputs": [],
      "source": [
        "#\n",
        "data.drop(['customerID', 'Charges.Total'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0fre_jufMlP"
      },
      "source": [
        "Let's print the classes of each column that is of the categorical type to understand which treatments and where they can be performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24u6gytafMlP"
      },
      "outputs": [],
      "source": [
        "#\n",
        "for i in data.select_dtypes(include=['object']).columns:\n",
        "    if len(data[i].unique()) > 2:\n",
        "       print(f\"{i}: {data[i].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws2pVFm-fMlP"
      },
      "source": [
        "It is possible to notice that some columns have the class `No phone service` and `No internet service` which is equivalent to the class `No`, that is, there is no service. For these classes, we will consider them as `No` to avoid duplicate information. Since there will be only two results `Yes` and `No`, we will replace them with a binary number, 1 and 0.\n",
        "\n",
        "In addition, the columns 'PaymentMethod', 'Contract' and 'InternetService' have more than 2 categories and because of this, we will encode the data of these columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8iirWeLfMlP"
      },
      "outputs": [],
      "source": [
        "#\n",
        "cols = ['PaymentMethod', 'Contract', 'InternetService']\n",
        "#\n",
        "data2 = data.drop(cols, axis=1)\n",
        "#\n",
        "data2.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5AoMsD2fMlQ"
      },
      "outputs": [],
      "source": [
        "#\n",
        "dictionary = {'No internet service':0,\n",
        "              'No phone service': 0,\n",
        "              'No': 0,\n",
        "              'Yes': 1,\n",
        "              'Male':0,\n",
        "              'Female':1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKuHmSp6fMlQ"
      },
      "outputs": [],
      "source": [
        "#\n",
        "data2 = data2.replace(dictionary)\n",
        "#\n",
        "data2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtDLxE05fMlQ"
      },
      "source": [
        "There are several ways to create encoding, two of which are Label Encoding and One-Hot Encoding.\n",
        "\n",
        "#### Types of encoding\n",
        "\n",
        "* `Label Encoding` - Renames classes with numeric values ​​from 1 to n, where n is the number of classes. There may be a hierarchy between classes.\n",
        "\n",
        "* `One-Hot Encoding` - Transforms variables into n binary columns, where n is the number of classes. All classes are analyzed equally; when a class occurs, the column will have the value 1 and when it does not occur, the value 0, which happens for the other columns created.\n",
        "\n",
        "In our case, we will choose the method that transforms variables into binary columns. To learn more about this method, see the documentation.\n",
        "\n",
        "- [OneHotEncoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).\n",
        "\n",
        "It is also possible to prepare this form of encoding with pandas [`get_dummies`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html). If you want to know more about this method and the first one, we recommend reading the article [Pandas Get Dummies (One-Hot Encoding) – pd.get_dummies()](https://amiradata.com/pandas-get-dummies/).\n",
        "\n",
        "Feel free to test both ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4riSBNVLfMlQ"
      },
      "outputs": [],
      "source": [
        "#\n",
        "ohe = OneHotEncoder(dtype=int)\n",
        "ohe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "cols_ohe = ohe.fit_transform(data[cols]).toarray()\n",
        "cols_ohe"
      ],
      "metadata": {
        "id": "v34WNYlX4uEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import sklearn\n",
        "print(sklearn.__version__)\n"
      ],
      "metadata": {
        "id": "xik4rytZ6HnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
        "ohe.get_feature_names_out(cols)"
      ],
      "metadata": {
        "id": "IhYTiVrb5PAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "data3 = pd.concat([data2, pd.DataFrame(cols_ohe, columns=ohe.get_feature_names_out(cols))], axis=1)"
      ],
      "metadata": {
        "id": "DDz91p5V27mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data3"
      ],
      "metadata": {
        "id": "1FQiHEPT3DOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inUMecJkfMlQ"
      },
      "source": [
        "Now we have data with only numeric values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hBaUS9ofMlR"
      },
      "source": [
        "## Data balancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNiJtRusfMlR"
      },
      "outputs": [],
      "source": [
        "plot_countplot(data_db=data3,\n",
        "               x='Churn',\n",
        "               titulo=\"Distribution of the Churn variable before balancing\",\n",
        "               label_x='Churn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4brxpo6fMlR"
      },
      "source": [
        "We can see from the graph above that the dataset has the **target** (column `'Churn'`) [unbalanced](https://www.alura.com.br/artigos/lidando-com-desbalanceamento-dados?utm_source=gnarus&utm_medium=timeline). If the model is created with the variable in this way, it may harm the learning and results.\n",
        "\n",
        "To avoid problems in the model's learning, we will perform the balancing using the [`SMOTE`](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html) method from the imblearn library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt6mzzIzfMlR"
      },
      "outputs": [],
      "source": [
        "X = data3.drop(['Churn'], axis = 1)\n",
        "y = data3['Churn']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49F8yMCXfMlR"
      },
      "outputs": [],
      "source": [
        "sm = SMOTE(random_state=SEED)\n",
        "X_res, y_res = sm.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTXmIRFyfMlR"
      },
      "outputs": [],
      "source": [
        "data4 = pd.concat([pd.DataFrame(X_res), pd.DataFrame(y_res)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILAvwOG7fMlR"
      },
      "outputs": [],
      "source": [
        "plot_countplot(data_db=data4,\n",
        "               x='Churn',\n",
        "               titulo=\"Distribution of the Churn variable after balancing\",\n",
        "               label_x='Churn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4aJy5mWfMlR"
      },
      "source": [
        "Now, `data4` has the values ​​of the **target** column with the same quantities, that is, they are balanced. Therefore, we will use `data4` to build the classification models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwQAO-lCfMlR"
      },
      "outputs": [],
      "source": [
        "data4.to_json('Telco-Customer-Churn-balancing.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z71tDtUXfMlS"
      },
      "source": [
        "## Creating the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFZRs8INfMlS"
      },
      "source": [
        "To start training, separate the data into **training** and **test**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD42plmOfMlS"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_res , y_res, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evXyftPpfMlS"
      },
      "source": [
        "### 1. SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRG5YKSgfMlS"
      },
      "source": [
        "The first model to be assembled is the **SVC** classifier. To assemble it, we use the [SVC method from the sklearn library](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
        "\n",
        "To learn more about this method, you can access the video [Nonlinear estimators and support vector machines from the Machine Learning course: introduction to classification with SKLearn](https://cursos.alura.com.br/course/machine-learning-introducao-a-classificacao-com-sklearn/task/46782)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5HwdzC1fMlS"
      },
      "outputs": [],
      "source": [
        "svc = SVC(random_state=SEED)\n",
        "svc.fit(X_train, y_train)\n",
        "y_pred_svc = svc.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OJnohDpfMlS"
      },
      "source": [
        "After training the model, we need to know how well it performed in its training. To do this, we collect the classifications from a data set unknown to the model, the test set.\n",
        "\n",
        "The responses from the evaluation of each item in the test set performed by the model can be checked to know how well it performed in its test. The evaluation consists of analyzing several metrics that inform the success of the model. The metrics we will evaluate are [**Accuracy**](https://cursos.alura.com.br/course/machine-learning-credit-scoring/task/92910), [**Precision, Recall and F1 Score**](https://cursos.alura.com.br/course/machine-learning-credit-scoring/task/92914) and the [**Confusion Matrix**](https://cursos.alura.com.br/course/machine-learning-credit-scoring/task/92912)\n",
        "\n",
        "We obtain these metrics using the `plot_matriz_confusao()` function to analyze the final result of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6jnX0LEfMlS"
      },
      "outputs": [],
      "source": [
        "labels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
        "categories = [\"No Churn\", \"Churn\"]\n",
        "plot_matrix_confusion(y_test,\n",
        "                      y_pred_svc,\n",
        "                      group_names=labels,\n",
        "                      categories=categories,\n",
        "                      figsize=(8, 6),\n",
        "                      title=\"Confusion matrix for the SVC classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a7Hk0S6fMlT"
      },
      "source": [
        "### 2. Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReBqkOsufMlT"
      },
      "source": [
        "The second model to be assembled is the **Decision Tree** classifier. To assemble it, we use the [Decision Tree method from the sklearn library](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
        "\n",
        "To learn more about this method, you can watch the video [Decision Trees: delving deeper into Machine Learning models](https://cursos.alura.com.br/course/arvores-decisao-aprofundando-modelos-machine-learning).\n",
        "\n",
        "After training the model, we test it and plot the confusion matrix and other metrics using the `plot_matriz_confusao()` function to analyze the final result of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3A2q0jzfMlT"
      },
      "outputs": [],
      "source": [
        "dtree = DecisionTreeClassifier(max_depth=5, random_state = SEED)\n",
        "dtree.fit(X_train, y_train)\n",
        "y_pred_dt = dtree.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltgeehDofMlT"
      },
      "outputs": [],
      "source": [
        "labels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
        "categories = [\"No Churn\", \"Churn\"]\n",
        "plot_matrix_confusion(y_test,\n",
        "                      y_pred_dt,\n",
        "                      group_names=labels,\n",
        "                      categories=categories,\n",
        "                      figsize=(8, 6),\n",
        "                      title=\"Confusion matrix for the Decision Tree classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvdla-r8fMlT"
      },
      "source": [
        "### 3. Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCNpDeF-fMlT"
      },
      "source": [
        "The second model to be assembled is the **Decision Tree** classifier. To assemble it, we use the [Random Forest method from the sklearn library](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
        "\n",
        "To learn more about this method, you can watch the video [Decision Trees: delving deeper into Machine Learning models](https://cursos.alura.com.br/course/arvores-decisao-aprofundando-modelos-machine-learning).\n",
        "\n",
        "After training the model, we test it and plot the confusion matrix and other metrics using the `plot_matriz_confusao()` function to analyze the final result of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wenqc5KpfMlX"
      },
      "outputs": [],
      "source": [
        "rforest = RandomForestClassifier(max_depth = 5, random_state=SEED)\n",
        "rforest.fit(X_train, y_train)\n",
        "y_pred_rf = rforest.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlewwQIifMlX"
      },
      "outputs": [],
      "source": [
        "labels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
        "categories = [\"No Churn\", \"Churn\"]\n",
        "plot_matrix_confusion(y_test,\n",
        "                      y_pred_rf,\n",
        "                      group_names=labels,\n",
        "                      categories=categories,\n",
        "                      figsize=(8, 6),\n",
        "                      title=\"Confusion matrix for the random forest classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tosBS30YfMlY"
      },
      "source": [
        "### Comparing the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0zAG-8IfMlY"
      },
      "source": [
        "After training and testing the **SVC**, **Decision Tree** and **Random Forest** models, we can compare the results obtained to find the best model.\n",
        "\n",
        "To do this, we collect the classification metrics of the three models and group them in a comparison table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlVVUpI-fMlY"
      },
      "outputs": [],
      "source": [
        "models = ['svc', 'decision tree', 'random forest']\n",
        "y_pred_train = [svc.predict(X_train), dtree.predict(X_train), rforest.predict(X_train)]\n",
        "y_pred_test = [y_pred_svc, y_pred_dt, y_pred_rf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbrwYvipfMlY"
      },
      "outputs": [],
      "source": [
        "table_models = compare_models_metrics('Recall', models, y_train, y_pred_train, y_test, y_pred_test).round(2)\n",
        "table_models"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "5920b5758d452ea2be3c84d3b52789bc04ee682949a6b0870d7691434146c726"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('machine_learning')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}