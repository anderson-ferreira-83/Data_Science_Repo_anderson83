{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anderson-ferreira-83/Data_Science_Repo_anderson83/blob/main/1_Alura_Voz/Week_4_model_validation/p4_Optimization_for_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4 - Optimization"
      ],
      "metadata": {
        "id": "T1u5dvjRjci8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "jsFw6W9C8n46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "r3iYJdls8qhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qurg1odmmeBe"
      },
      "source": [
        "For the final presentation of our analysis for Alura Voice, we need to define the best model and use the best hyperparameters in it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RK93q7UmeBh"
      },
      "source": [
        "### Importing libraries\n",
        "\n",
        "For the application we will use `pandas`, `seaborn`, `sklearn`, `imblearn` and `sys`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Link to access the functions of model\n",
        "str_utils = '1DJEF0jli6eQixbcz-ARBX7X5d9ojoP4J'"
      ],
      "metadata": {
        "id": "SiTLgku19MP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading file to current GoogleColab directory 'utils.py'\n",
        "!gdown --id $str_utils"
      ],
      "metadata": {
        "id": "oDV7zK1L9OcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from utils import plot_countplot,plot_matrix_confusion, compare_models_metrics"
      ],
      "metadata": {
        "id": "qtdjVf2x9Jh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLUb4dGbmeBh"
      },
      "outputs": [],
      "source": [
        "#\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "#\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgD2DA5ymeBi"
      },
      "source": [
        "## Optimizing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgzFnX76meBi"
      },
      "source": [
        "Knowing that it is necessary to choose the best developed model, we will analyze the result obtained in the [previous study](https://github.com/sthemonica/challenge_dados_1/blob/bruno/3-Modelos%20de%20ML/modelos.ipynb), ordered by the Recall value:\n",
        "\n",
        "<h3>Table of models ordered by Recall</h3>\n",
        "\n",
        "|    | Model          | Training Accuracy | Test Accuracy | Precision | Recall | F1-Score |\n",
        "|---:|:---------------|------------------:|--------------:|----------:|-------:|---------:|\n",
        "|  0 | random forest  |              0.81 |          0.80 |      0.77 |   0.85 |     0.81 |\n",
        "|  1 | decision tree  |              0.81 |          0.80 |      0.78 |   0.85 |     0.81 |\n",
        "|  2 | svc            |              0.75 |          0.75 |      0.73 |   0.78 |     0.75 |\n",
        "\n",
        "\n",
        "***Recall*** is a metric that evaluates whether positive predictions were given correctly, that is, it evaluates the number of True Positives (True Pos) and False Negatives (False Neg). Therefore, the higher the Recall, the more correct the model obtained.\n",
        "\n",
        "Therefore, we will use the model that obtained the best Recall, therefore, Random Forest.\n",
        "\n",
        "Having chosen the best model, we will use [GridSearchCV](https://cursos.alura.com.br/course/machine-learning-otimizacao-de-modelos-atraves-de-hiperparametros/task/48715) to optimize it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OsNCEPGmeBj"
      },
      "source": [
        "Now, let's read the dataset worked on in the previous notebook `models.ipynb` through the pandas `read_json` method:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Link to access the shared database file 'Telco-Customer-Churn-balancing.json'\n",
        "str_data_telco_cust_churn_balanc_file = '1pwoPlr7KE5mIuTae54mJYxVfe9nC-BzQ'"
      ],
      "metadata": {
        "id": "fomB5w8M9llt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading file to current GoogleColab directory 'Telco-Customer-Churn-balancing.json'\n",
        "!gdown --id $str_data_telco_cust_churn_balanc_file"
      ],
      "metadata": {
        "id": "xu4s39BZjndz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00LYhLgGmeBj"
      },
      "outputs": [],
      "source": [
        "data = pd.read_json('Telco-Customer-Churn-balancing.json')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnN7HM0YmeBk"
      },
      "source": [
        "To optimize the model, we first need to create the training and testing set. In this way, we divide the dataset into input (X) and output (y), or target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITS_IIpKmeBk"
      },
      "outputs": [],
      "source": [
        "X = data.drop(['Churn'], axis=1)\n",
        "y = data['Churn']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jhFa2-ImeBk"
      },
      "source": [
        "And so we can separate the data into training and testing with `train_test_split`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tI7dvF-OmeBk"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs33Yh16meBk"
      },
      "source": [
        "It is necessary to define the hyperparameters to be optimized by GridSearchCV, which are:\n",
        "\n",
        "* **`n_estimators`**: number of decision trees;\n",
        "* **`criterion`**: decision criterion;\n",
        "* **`max_features`**: maximum number of variables to be used when searching for the best division;\n",
        "* **`max_depth`**: maximum depth of the decision tree;\n",
        "* **`min_samples_split`**: minimum number of samples required for a division to be made;\n",
        "* **`min_samples_leaf`**: minimum number of samples required for a leaf to be formed;\n",
        "* **`bootstrap`**: indicates whether data resampling was performed when creating the decision tree models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUUEKoNsmeBl"
      },
      "outputs": [],
      "source": [
        "n_estimators = np.arange(100, 200, step=20)\n",
        "criterion = [\"gini\", \"entropy\"]\n",
        "max_features = [\"auto\", \"log2\"]\n",
        "max_depth = list(np.arange(2, 10, step=2))\n",
        "min_samples_split = np.arange(2, 10, step=2)\n",
        "min_samples_leaf = [2, 4]\n",
        "bootstrap = [True, False]\n",
        "\n",
        "parameters = {\n",
        "    \"n_estimators\": n_estimators,\n",
        "    \"criterion\": criterion,\n",
        "    \"max_features\": max_features,\n",
        "    \"max_depth\": max_depth,\n",
        "    \"min_samples_split\": min_samples_split,\n",
        "    \"min_samples_leaf\": min_samples_leaf,\n",
        "    \"bootstrap\": bootstrap,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APIJpiDDmeBl"
      },
      "source": [
        "Now, we can use the GridSearchCV optimizer to improve the *Recall* metric. To do this, we created a GridSearchCV object and passed our model, the hyperparameters defined previously, and the metric to be optimized, *Recall*, as parameters. We also performed the adjustment using the `fit()` method.\n",
        "\n",
        "To learn more about GridSearchCV and its parameters, you can consult the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mCLiS0jmeBl"
      },
      "outputs": [],
      "source": [
        "clf = GridSearchCV(RandomForestClassifier(random_state=SEED), parameters, cv=3, n_jobs=-1, scoring=\"recall\")\n",
        "clf.fit(x_train, y_train)  # ajuste com os dados de treino"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzb2rli2meBl"
      },
      "source": [
        "After the adjustment, we were able to analyze the results obtained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o661Hl3meBl"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(clf.cv_results_).sort_values(by=\"rank_test_score\").head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I62A03elmeBl"
      },
      "source": [
        "To obtain the best results from the optimizer we use the **`best_params_`** command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMXEGukmmeBl"
      },
      "outputs": [],
      "source": [
        "clf.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmxgPzDZmeBm"
      },
      "source": [
        "With this, we were able to create a Random Forest estimator with the best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0X8NDoQJmeBm"
      },
      "outputs": [],
      "source": [
        "rforest = RandomForestClassifier(**clf.best_params_, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLeCuaRdmeBm"
      },
      "outputs": [],
      "source": [
        "model = rforest.fit(x_train, y_train)  # treinamento com os dados de treino\n",
        "y_pred = rforest.predict(x_test)  # realizando as predições"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-A1dkjwmeBm"
      },
      "source": [
        "We can analyze whether the model actually obtained better results in the *Recall* metric using the `plot_matriz_confusao` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujtENn8omeBm"
      },
      "outputs": [],
      "source": [
        "labels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
        "categories = [\"Não Churn\", \"Churn\"]\n",
        "plot_matrix_confusion(y_test,\n",
        "                      y_pred,\n",
        "                      group_names=labels,\n",
        "                      categories=categories,\n",
        "                      figsize=(8, 6),\n",
        "                      title=\"Matriz de confusão para o classificador Random Forest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWQ3iMNFmeBm"
      },
      "outputs": [],
      "source": [
        "print(f\"Training accuracy: {rforest.score(x_train, y_train) * 100:.2f}%\")  # Checking training accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewCMJW9DmeBm"
      },
      "source": [
        "It can be seen that recall and other metrics increased with the optimized model.\n",
        "\n",
        "<h4>Before optimization</h4>\n",
        "\n",
        "|    | Model          | Training Accuracy | Test Accuracy | Precision | Recall | F1-Score |\n",
        "|---:|:---------------|------------------:|--------------:|----------:|-------:|---------:|\n",
        "|  0 | random forest  |              0.81 |          0.80 |      0.77 |   0.85 |     0.81 |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>After optimization</h4>\n",
        "\n",
        "|    | Model          | Training Accuracy | Test Accuracy | Precision | Recall | F1-Score |\n",
        "|---:|:---------------|------------------:|--------------:|----------:|-------:|---------:|\n",
        "|  0 | random forest  |              0.85 |          0.82 |      0.79 |   0.86 |     0.83 |\n"
      ],
      "metadata": {
        "id": "TCkQXD1DK6rd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84NFUvoJmeBn"
      },
      "source": [
        "This way, we were able to create a well-optimized model and present it to Alura Vocing."
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "5920b5758d452ea2be3c84d3b52789bc04ee682949a6b0870d7691434146c726"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('machine_learning')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}